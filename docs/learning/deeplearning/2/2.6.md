# 概率
## 基本概率论
**大数定律（law of large numbers）**告诉我们：随着投掷次数的增加，这个估计值会越来越接近真实的潜在概率。

在统计学中，我们把从概率分布中抽取样本的过程称为**抽样（sampling）**.把概率分配给一些离散选择的分布称为**多项分布（multinomial distribution）**.

### 概率论公理
当处理骰子掷出时，我们将集合$S=\{1,2,3,4,5,6\}$称为**样本空间（sample space）**或**结果空间（outcome space）**，其中每个元素都是**结果（outcome）**.**事件（event）**是一组给定样本空间的随机结果。

**概率（probability）**可以被认为是集合映射到真实值的函数。在给定的样本空间$S$中，事件$A$的概率，表示为$P(A)$,满足以下属性：

- 对于任意事件$A$,其概率从不会是负数，即$P(A)\geq 0$。
- 整个样本空间的概率为1，即$P(S)=1$。
- 对于**互斥（mutually exclusive）**事件（对于所有$i\neq j$都有$A_i\cap A_j=\emptyset$）的任意一个可数序列$A_1,A_2,\cdots$，序列中任意一个事件发生的概率等于它们各自发生的概率之和,即$P(\cup_{i=1}^{\infty}A_i)=\sum_{i=1}^{\infty}P(A_i)$。

### 随机变量
一方面，我们可以将$P(X)$表示随机变量$X$上的**分布（distribution）**：分布告诉我们$X$获得某一值的概率。另一方面，我们可以简单用$P(a)$表示随机变量取值$a$的概率.

请注意，**离散（discrete）**随机变量（如骰子的每一面）和**连续（continuous）**随机变量（如人的体重和身高）之间存在微妙区别.
在一些情况下，我们将这个看到某个数值的可能性量化为**密度（density）**。高度恰好为1.80米的概率为0，但密度不是0.

## 处理多个随机变量
当处理多个随机变量时，会有若干个变量是我们感兴趣的。
### 联合概率
**联合概率（joint probability）**$P(A=a,B=b)$.给定任意值a和b，联合概率可以回答：$A=a$和$B=b$同时满足的概率是多少？
### 条件概率
通过联合概率的不等式，我们得到一个比率:$0\leq \frac{P(A=a,B=b)}{P(A=a)}\leq 1$,我们称这个比率为**条件概率（conditional probability）**，并用$P(B=b|A=a)$表示它：它是$B=b$在$A=a$条件下发生的概率。
### 贝叶斯定理
通过条件概率的定义，我们可以的出统计学中最有用的方程之一：**Bayes定理（Bayes' theorem）**.

$$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$$

### 边际化
为了能进行事件概率求和，我们需要**求和法则（sum rule）**，即$B$的概率相当于计算$A$的所有可能选择，并将所有选择的联合概率聚合在一起。

$$P(B)=\sum_{A}P(A,B)$$

这也称为**边缘化（marginalization）**.边际化结果的概率或分布称为**边际概率（marginal probability）**或**边缘分布（marginal distribution）**。

### 独立性
另一个有用的属性是**依赖（dependence）**与**独立（independence）**。

如果两个随机变量$A$和$B$是独立的。统计学家通常将这一点表述为$A\bot B$，此时有$P(A|B)=P(A)$，$P(B|A)=P(B)$，$P(A,B)=P(A)P(B)$。

### 期望和方差
一个随机变量$X$的**期望（expectation，或平均值（average））**表示为

$$E[X]=\sum_{x}xP(X=x)$$
当函数$f(x)$的输入是从分布$P$中抽取的随机变量时，$f(x)$的期望表示为

$$E_{x~P}[f(x)]=\sum_{x}f(x)P(X=x)$$
在许多情况下，我们希望衡量随机变量$X$与其期望值的偏置。这可以通过方差来量化

$$Var[X]=E[(x-E[X])^2]=E[X^2]-E[X]^2$$
方差的平方根被称为**标准差（standard deviation）**。随机变量函数的方差衡量的是：当从该随机变量分布中采样不同值$x$时，函数值偏离该函数的期望的程度：

$$Var[f(x)]=E[(f(x)-E[f(x)]^2)]$$


