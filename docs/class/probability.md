> 我们为什么需要概率论？当我们掌握不完全的信息或不确定的知识，而又希望做出判断时，我们就需要概率论。

> 不同的理论有不同的视角，若一个问题要用特定的理论去解决，那么必须要遵循其理论的视角。

> 若无法处理特殊化的问题， 或许可以先解决一般化的问题再进行推广。


## 事件及其概率
### 随机现象与统计规律性
#### 随机现象

在这世界上存在着三种事件，一是必然发生的**必然事件**，二是必然不会发生的**不可能事件**，三则是结果无法预见的**随机事件**。

#### 概率的统计定义
在重复N次的试验中，事件A出现的次数被称为**频数**，而下式

$$F_N(A)=\frac{n}{N}$$

则为A在N次试验中出现的**频率**

当N无限增大时，频率趋向稳定的那个常数可以表示事件A在一次试验中发生的可能性的大小，称作**频率**，记为$P(A)$,概率的这种定义称为**统计定义**

频率的稳定性->大数定律

**概率的性质**：非负性、规范性（对于必然事件$\Omega, F_N(\Omega)=N/N=1$）、可加性.

### 古典概型

> 两种方法：1.样本清点 2.逐事件概率叠加+数量

#### 样本空间和样本点

随机实验的每一基本结果称为**样本点（sample point）**，通常记作$\omega$.

样本点的全称称为**样本空间（sample space）**，通常记作$\Omega$

#### 古典概型

古典概型的两个特征：

- 样本空间是有限的，$\Omega=\{\omega_1,\omega_2,\cdots,\omega_n \}$
- 各基本事件的出现是等可能的，即它们发生的概率相同

计算概率的近似公式

$$P(B)=\frac{N(N-1)\cdots(N-n+1)}{N^n} =exp\{-\frac{n(n-1)}{2N}\}.$$

>重要思想：特定样本数与样本空间的总量的比率成为其概率. 但要注意的是样本空间的限制(明确问题的描述是重点)，如何确定样本空间的总量.

#### 几何概率

当有无限个样本点时。$事件A_g=\{任取一个样本点，它落在区域g\subset\Omega\}$,则$A_g$的概率定义为

$$P(A_g)=\frac{g的测度}{\Omega的测度}$$

这样定义的概率被称为**几何概率**

> 其最主要的思想是：在样本数推广到无限时，再去以古典概型类似的思想来表达概率，就通过引入测度的概率来实现。从比较他们个数本身，推广的比较他们的测量值.

---

> 前面的概率都是我们朴素地去理解，通过数和测量比较的方法去定义概率。接下来我们需要更加规范的表达，来推进我们对于概率的研究.

### 概率的公理化定义
#### 事件

引入集合论来讨论事件之间的关系。

> T1.用数学归纳法证明n个事件并的概率公式

> T2.如果$A_1,A_2,\cdots,A_n,\cdots$是一列相互独立事件，假设$(i)P(A_n)=1/n,(ii) P(A_n)=1/n^2,$求$P(\cup^\infty_{n=m}A_n),$其中$m \geq 1$?PS：一系列集合的并的反面为其补集的交.

>T3.投票选举甲、乙两人，已知甲共得m张，乙共得n张，$m>n$.在计票过程中(1)甲得票数时钟超过乙得票数的概率;(2)甲得票数始终不低于乙得票数的概率. PS:票差-总票图,重点不在于起始点，而是上下翻折样本数的相同.

> 容斥原理的应用(从集合的角度考虑问题)：某题库有20道题，测验时系统随机分给$n(n\geq 20)$个考生，每个考生一道题.求所有20道题能完全分配下去的概率.

#### 概率空间

概率空间包含三个要素：

- 样本空间$\Omega$
- 事件域$F$
	- $\Omega \in F$
	- $若A\in J, 则\bar{A}\in F;$
	- $若A_1, A_2, \cdots, A_n,\cdots,\in F,则\cup^{\infty}_{n=1}A_n \in F$

	满足以上条件的$F$被称为$\Omega$上的$\sigma-域$或$\sigma-代数$.$F$中的元素称为事件

	> 其本质即对并补运算都封闭的集合域.

- 概率是定义在$F$上的实值集函数：$A(\in F)\to^P P(A)$

### 条件概率与事件的独立性
#### 条件概率

> 其对应的是有信息情况下的推论

$$P(A|B)=\frac{P(AB)}{P(B)}$$

#### 全概率公式，贝叶斯公式

全概率公式： 对信息的综合推断

$$P(B)=\sum^{\infty}_{i=1}P(A_i)P(B|A_i)$$

贝叶斯公式：利用已知信息反推原事件的概率

$$P(A_i|B)=\frac{P(A_i)·P(B|A_i)}{\sum^{\infty}_{k=1}P(A_k)·P(B|A_k)}$$

#### 事件独立性

> 举例说明$P(ABC)=P(A)P(B)P(C)$不能推出$A,B,C$两两独立(从样本数去思考)


独立性:即事件$A$的发生不会影响事件$B$的发生的概率

$$P(AB)=P(A)P(B)$$

## 随机变量与分布函数

>其更加推进的一步是：从等可能事件推广到了概率在不同事件上的分布.故称随机变量。

### 离散型随机变量及其分布

#### 随机变量的概念

用于表示随机实验的结果，$w$为样本点，则$\xi$可表示为依$w$不同而取不同值得函数.$\xi =\xi(w)$

#### 离散型随机变量

$$\left[\begin{array}{ll}
x_1& x_2 & \cdots &x_n &\cdots&\\
p(x_1)&p(x_2)&\cdots &p(x_n) &\cdots&
\end{array}\right]$$

分布列如上：

### 分布函数与连续性随机变量
#### 分布函数

> 我们希望将分布列推广，从而对所有的随机变量有统一的概率表达方式

$$F(x)=P(\xi \leq x) \qquad -\infty<x<\infty$$

#### 连续性随机变量及密度函数

> 针对连续性的随机变量，我们可以更进一步地研究其概率在整个域上的分布情况，而非总体的情况.

- 定义：若随机变量$\xi$可取某个区间（有限或无限）中的一切值，并且存在某个非负的可积函数$p(x)$，使分布函数$F(x)$满足

$$F(x)=\int^x_{-\infty}p(y)dy,\qquad -\infty < x<\infty,$$

则称$\xi$为连续型随机变量，称$p(x)$为$\xi$的概率密度函数，简称为密度函数.

### 随机向量

> 当同时研究多个变量的概率关系时，我们就要将随机变量替换成随机向量.同时引出联合分布以及边际分布的概念.

所谓边际分布，即考虑到其他变量的所有可能的情况下，某一变量的概率分布情况.

#### 分布函数

其分布函数与一元分布有类似的性质.但同时也有额外条件

$$F(b_1,b_2)-F(a_1,b_2)-F(b_1,b_2)+F(a_1,a_2)\geq 0$$

#### 连续性随机向量

并无其他，将加减法转换成了积分运算.

### 随机变量的独立性

> 只需要看其随机变量的边际分布能否推得联合分布.

### 随机变量的函数及其分布

简单的变换：卷积公式

1.当$\xi_1$与$\xi_2$仙湖独立，各自有密度函数$p_1(x),p_2(x)$时，$\xi_1 + \xi_2$的密度函数为

$$p_\eta(z)=\int^{\infty}_{-\infty}p_1(x)p_2(z-x)dx$$

2.若$(\xi_1, \xi_2)$是连续型随机变量，则$\eta=\xi_1/\xi_2$是连续型随机变量，其密度函数为

$$p_\eta(z)=\int^{\infty}_{-\infty}p(zx,x)|x|dx$$

3.次序统计量的分布

$\xi_1^* = min\{\xi_1,\xi_2,\cdots,\xi_n\}, \xi_n^*=max\{\xi_1,\xi_2,\cdots,\xi_n\}$

(1).$\xi_n^*$的分布函数

$$P(\xi_n^*\leq x)= P(\xi_1 \leq x,\xi_2 \leq x,\cdots,\xi_n\leq x)=[F(x)]^n$$

(2).$\xi_1^*$的分布函数

$$P(\xi_1^* > x) = [1-F(x)]^n,\qquad P(\xi_1^*\leq x) = 1-[1-F(x)]^n$$

(3).$(\xi_1^*,\xi_n^*)$的联合分布函数

$$F(x,y)=P(\xi_1^*\leq x, \xi_n^*\leq y) = [F(y)]^n-[F(y)-F(x)]^n$$

#### 随机向量的变换
$$q(y_1,\cdots,y_n)=p(x_1(y_1,\cdots,y_n),\cdots,x_n(y_1,\cdots,y_n))|J|$$


## 数字特征与特征函数
### 数学期望
>我们不仅希望了解事情发展的可能性，还希望了解一个行动是否有益，是否有期望的收益，多大程度上能得到期望的收益.


- 离散型随机变量的数学期望

简单计算

- 连续型随机变量的数学期望

积分计算
#### 数学期望的基本性质

1. 若$|\xi|\leq\eta$,且$E\eta$存在，则$E\xi$存在，且$|E\xi|\leq E|\xi|\leq E\eta$

2. 若$E\xi_1,\cdots,E\xi_n$存在，则对任意常数$c_1,\cdots,c_n$，及$b$,$E(\sum^n_{i=1}c_i\xi_1+b)$存在，且

$$E(\sum^n_{i=1}c_i\xi_i+b)=c_i\sum^n_{i=1}E\xi_i+b$$

#### 条件期望

即条件概率下的期望、同时存在全期望公式.

### 方差、协方差与相关系数
#### 方差

>计算偏离期望的大小

$$Var\xi = E(\xi - E\xi)^2，\qquad Var\xi = E\xi^2 -(E\xi)^2 $$

#### 协方差
- 定义：设$\xi_i$和$\xi_j$的联合分布函数为$F_{ij}(x,y).$若$E|(\xi_i-E\xi_i)(\xi_j-E\xi_j)|<\infty,$称

$$E(\xi_i-E\xi_i)(\xi_j-E\xi_j)=\int^{\infty}_{-\infty}\int^{\infty}_{-\infty}(x-E\xi_i)(y-E\xi_j)dF_{ij}(x,y)$$

为$\xi_i$和$\xi_j$的协方差,记作$Cov(\xi_i,\xi_j).$

- 性质1 $Cov(\xi,\eta)=Cov(\eta,\xi)=E\xi \eta - E\xi E\eta$

协方差矩阵$\Sigma = \frac{1}{n-1} X^TX$

#### 相关系数

$$r_{\xi\eta}=Cov(\xi^*,\eta^*)=\frac{E(\xi-E\xi)(\eta-E\eta)}{\sqrt{Var\xi Var\eta}}$$

不相关则上式为0.
#### 矩

原点矩:$m_k = E\xi^k$

中心矩:$c_k=E(\xi-E\xi)^k$

其代表随机变量的一系列的数字特征，具有普遍意义

### 特征函数

> 特征函数是随机变量分布的另外一种描述形式，即包含了此随机变量分布的所有特征

#### 定义

设$\xi$为实随机变量，称

$$f(t)=Ee^{it\xi},\space -\infty < t < \infty$$

为$\xi$的特征函数(characteristic function)

- 离散型计算

$$f(t)=\sum^{\infty}_{n=1}p_ne^{itx_n}$$

- 连续性计算

$$f(t)=\int^{\infty}_{-\infty}e^{itx}p(x)dx$$

- 练习各种分布的特征函数计算

#### 性质
#### 逆转公式与唯一性定理

逆转公式

- 设分布函数$F(x)$的特征函数为$f(t)$,令$x_1,x_2$是$F(x)$的连续点，则

$$F(x_2)-F(x_1)=\lim_{T\to\infty}\frac{1}{2\pi}\int^T_{-T}\frac{e^{-itx_1}-e^{-itx_2}}{it}f(t)dt$$

唯一性定理

- 分布函数可由特征函数唯一确定.

逆傅里叶变换

- 设$f(t)$是特征函数，且$\int^\infty_{-\infty}|f(t)|dt < \infty (f(t) 绝对可积)$,则分布函数$F(x)$的导数存在且连续.此时

$$F'(x)=\frac{1}{2\pi}\int^\infty_{-\infty}e^{-itx}f(t)dt$$

#### 分布函数的可加性

#### 多元特征函数

### 多元正态分布

#### 密度函数和特征函数

#### 性质

## 极限定理

逆极限定理：

- 设$f_n(t)$是分布函数$F_n(x)$的特征函数，如果对每个$t,f_n(t)\to f(t)$,且$f(t)$在$t=0$处连续，则$f(t)$一定是某个分布函数$F$的特征函数，且$F_n \to^w F$

### 依分布收敛与中心极限定理
#### 分布函数弱收敛

>由于分布函数刻画了其对应的随机变量的全部概率性质，因此对随机变量序列的研究就可以转换为对相应分布函数序列的研究

#### 弱收敛的定义

>概率分布上的逼近性

设$F$是一分布函数，$\{F_n\}$是一列分布函数.如果对$F$的每个连续点$x\in \textbf{R}$，当$n\to \infty$时，都有$F_n(x)\to F(x)$,则称$F_n$**弱收敛**（weakly converges）于$F(x)$，记作$F_n \to^w F$.

对应的随机变量$\{\xi_n\}$被称为**依分布收敛**（converges in distribution）于$\xi$,记作$\xi_n \to^d \xi$ 

#### 性质
#### 中心极限定理

> n足够大的二项分布符合中心极限定理

- 证明
  - 设$\{\xi_n\}$是一列随机变量.如果存在常数$B_n>0$与$A_n$使得$$\frac{1}{B_n}\sum^n_{k=1}\xi_k-A_n \to ^dN(0,1)$$

二项分布的近似

=== "德莫夫-拉普拉斯定理"
	- 设$\Phi(x)$为标准正态分布的分布函数，对$-\infty < x <\infty$,有

	$$\lim_{n\to \infty}P(\frac{S_n-np}{\sqrt{npq}}\leq x)=\Phi(x)$$

=== "林德贝格-勒维定理"

	当$n$很大，$p$大小适中时，有

	$$P(\alpha < S_n \leq \beta) =P(\frac{\alpha -np}{\sqrt{npq}} < \frac{S_n - np}{\sqrt{npq}} \leq \frac{\beta -np}{\sqrt{npq}})\approx \phi(\frac{\beta-np}{\sqrt{npq}})-\phi(\frac{\alpha-np}{\sqrt{npq}}) $$

	- 设$\{\xi_n\}$是一列独立同分布的随机变量，记$S_n=\sum^n_{k=1}\xi_k,E\xi_1 = a,Var\xi_1=\sigma^2$.则中心极限定理成立，即

	$$\frac{S_n-na}{\sqrt{n}\sigma}\to^d N(0,1)$$

=== "林德贝格-费勒定理"

	- 设$\{\xi_k\}$为独立随机变量序列，则

	$$\lim_{n\to \infty }\frac{1}{\sum^n_{k=1}Var\xi_k}\max_{1\leq k\leq n}Var\xi_k = 0$$

	与

	$$\frac{\sum^n_{k=1}(\xi_k-E\xi_k)}{\sqrt{\sum^n_{k=1}Var\xi_k}} \begin{CD} @>d>>\end{CD} N(0,1)$$
	成立的充要条件是林德贝格条件被满足：对任意的$r>0$,

	$$\frac{1}{\sum^n_{k=1}Var\xi_k}\sum^n_{k=1}\int_{|x-E\xi_k|\geq r\sqrt{\sum Var\xi_k}}(x-E\xi_k)^2dF_k(x)\to 0$$

=== "李雅普诺夫(Lyapunov)定理"

	- 若对独立随机变量序列$\{\xi_k\}$,存在常数$\delta >0$,使得当$n\to \infty$时有

	$$\frac{1}{(\sum^n_{k=1}Var\xi_k)^{1+\delta/2}}\sum^n_{k=1}E|\xi_k-E\xi_k|^{2+\delta}\to 0$$

	则中心极限定理成立

### 依概率收敛与弱大数定理
#### #### 依概率收敛定义

>分布函数刻画了随机变量取值的分布规律，但是却无法描述两个随机变量取值之间的接近程度.因此我们需要定义**依概率收敛**

如

$$\xi(w)=\left\{\begin{array}{ll}
1, && w\in [0,0.5] \\
0, && w\in (0.5,1]
\end{array}\right. \qquad \eta(w)=\left\{\begin{array}{ll}
0, && w\in[0,0.5], \\
1, && w\in(0.5,1],
\end{array}\right. $$

即使他们具有相同的分布函数

$$F(x)=\left\{\begin{array}{ll}
0, && x < 0, \\
\frac{1}{2}, && 0 \leq x < 1,\\
1, && x \geq 1. 
\end{array}
\right.
$$

如果定义$\xi_n = \xi, n \geq 1,$则$\xi_n \to^d \eta$，但是$|\xi_n-\eta|=1$.

设$\xi$和$\xi_n,n\geq1$，是定义在同一概率空间上的随机变量，如果对任意$\epsilon >0$,

$$\lim_{n \to \infty}P(|\xi_n-\xi|\geq\epsilon)=0$$

或者

$$\lim_{n\to\infty}P(|\xi_n - \xi|<\epsilon)=1$$

则称$\xi_n$依概率收敛于$\xi$，记作$\xi_n \to^P \xi$

>不仅在分布上逼近，在取值上也逼近.

#### 定理

设$\xi$和$\xi_n,n\geq 1$是定义在概率空间上的随机变量.

1. 如果$\xi_n \to^P \xi$,则$\xi_n \to^d \xi$.

2. 如果$\xi_n \to^d c$,其中$c$为常数,则$\xi_n\to^P c$.

#### 弱大数定律

伯努利大数定律

>二项分布的试验结果向概率的趋近性.

- 设$\{\xi_n\}$是一系列独立同分布的随机变量，$P(\xi_n=1)=p,P(\xi_n=0)=1-p,0 < p < 1.$记$S_n=\sum^n_{i=1}\xi_i$,则

$$\frac{S_n}{n}\begin{CD}@>P>>\end{CD}p.$$

定义4.4：设$\{\xi_n\}$是定义在概率空间$(\Omega, F,P)$上的随机变量序列，如果存在常数列$\{a_n\}$和$\{b_n\}$，使得

$$\frac{1}{a_n}\sum^n_{k=1}\xi_k -b_n\to^P0,$$

则称$\{\xi\}$服从弱大数定律，简称$\{\xi_n\}$服从大数定律

=== "切贝雪夫大数定律"

	- 设$\{\xi_n\}$是定义在概率空间$(\Omega, F, P)$上的随机变量序列，$E\xi_n=\mu_n, Var\xi_n=\sigma_n^2.$如果$\sum^n_{k=1}\sigma^2/n^2\to0$，则$\{\xi_n\}$服从弱大数定律,即

	$$\frac{1}{n}\sum^n_{k=1}\xi_k-\frac{1}{n}\sum^n_{k=1}\mu_k \begin{CD} @>P>> \end{CD}0$$


=== "辛钦大数定律"

	>独立同分布则综合结果向期望靠近

	- 设$\{\xi_n\}$是定义在概率空间$(\Omega, F , P)$上的独立同分布随机变量序列，$E|\xi_1|<\infty$，记$\mu=E\xi_1, S_n=\sum^n_{k=1}\xi_k$.则$\{\xi_n\}$服从弱大数定律，即

	$$\frac{S_n}{n}\begin{CD} @>P>> \end{CD}\mu$$


### 以概率1收敛与强大数定律
#### 以概率1收敛

> 缩小域，只针对概率为1的集合来说

- 定义：设$\xi$和$\xi_n,n\geq 1$,是定义在概率空间$(\Omega,F,P)$上的随机变量.

1. 如果存在$\Omega_0 \in F$,使得$P(\Omega_0) = 1$,且对任意$\omega \in \Omega_0$,有$\xi_n(\omega) \to \xi(\omega),$则称$\xi_n$以概率1收敛,或**几乎必然收敛**于$\xi$,记作$\xi_n \to \xi a.s.$

2. 如果存在$\Omega_0 \in F$,使得$P(\Omega_0)=1$,且对任意$\omega \in \Omega_0$,数列$\{\xi_n(\omega)\}$是柯西基本列,即$\xi_n(\omega)-\xi_m(\omega)\to 0(n > m \to \infty)$，则称$\xi_n$以概率1是柯西基本列

判别准则：

- 定理：设$\xi$和$\xi_n,n\geq 1,$是定义在概率空间$(\Omega,F,P)$上的随机变量.

1. $\xi_n \to \xi a.s.$当且仅当对任意$\epsilon > 0,$

$$\lim_{n \to \infty}P(\sup_{k \geq n}|\xi_k - \xi| \geq \epsilon) = 0$$

2. $\{\xi_N\}$以概率1是柯西基本列当且仅当对任意$\epsilon > 0,$

$$\lim_{n \to \infty}P(\sup_{k \geq0}|\xi_{k+n}-\xi_k|\geq \epsilon) = 0$$

#### 强大数定律

- 定义：设$\{\xi_n\}$是定义在概率空间$(\Omega, F, P)$上的随机变量序列，如果存在常数列$\{a_n\}$和$\{b_n\}$,使得

$$\frac{1}{a_n}\sum^n_{k=1}\xi_k - b_n \to 0\quad a.s.$$

则称$\{\xi_n\}$服从强大数定律.

#### 波雷尔强大数定律

设$\{\xi_n\}$是定义在概率空间$(\Omega, F, P)$上的独立同分布随机变量序列，$P(\xi_n=1p, P(\xi_n = 0)) = 1-p, 0 < p < 1.$记$S_n = \sum^n_{k=1}\xi_k,$则

$$\frac{S_n}{n}\top a.s.$$

#### 柯尔莫哥洛夫强大数定律

> 从二项分布到一般随机变量的推广

设$\{\xi_n\}$是定义在概率空间$(\Omega,F,P)$上的独立同分布随机变量序列，$E|\xi_1|<\infty,\mu=E\xi_1.$记$S_n = \sum^n_{k=1}\xi_k$,则

$$\frac{S_n}{n}\to \mu \quad a.s.$$